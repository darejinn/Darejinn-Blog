<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-05-12T13:51:20+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">DaRe_jin’s Blog</title><subtitle>내실 있는 낙관</subtitle><author><name>DaRe_jin</name></author><entry><title type="html">희소함의 당위</title><link href="http://localhost:4000/thoughts/05.-%ED%9D%AC%EC%86%8C%ED%95%A8%EC%9D%98-%EB%8B%B9%EC%9C%84/" rel="alternate" type="text/html" title="희소함의 당위" /><published>2025-05-09T00:00:00+09:00</published><updated>2025-05-12T00:00:00+09:00</updated><id>http://localhost:4000/thoughts/05.%20%ED%9D%AC%EC%86%8C%ED%95%A8%EC%9D%98%20%EB%8B%B9%EC%9C%84</id><content type="html" xml:base="http://localhost:4000/thoughts/05.-%ED%9D%AC%EC%86%8C%ED%95%A8%EC%9D%98-%EB%8B%B9%EC%9C%84/"><![CDATA[<hr />

<p class="notice--info">원칙은 바뀔 수 있음이 원칙이다.</p>

<h1 id="introduction">Introduction</h1>

<p>사람은 익숙하지 않은 것에서 흥미를 느낀다.</p>

<p>따라서 타인이 나를 주목하게 만드는 일은 그리 어렵지 않다. 다수와 다른 무언가를 하면 된다.</p>

<ul>
  <li>
    <p>모두가 말할 때 말을 하지 않는 것, 그리고 아무도 말하지 못할 때 목소리를 내는 것.</p>
  </li>
  <li>
    <p>중요하지 않아 보이는 일에 사력을 다하는 것, 그리고 모두가 목매는 일을 가벼이 넘겨버리는 것.</p>
  </li>
</ul>

<p>희소함은 ‘나’라는 존재를 타인에게 어필하는 좋은 도구이다. 이 새로움에 일관적으로 나의 색이 드러날 때, ‘나’는 ‘관종’이 아닌 ‘특별한 사람’으로 인지된다. 타인이 나에게 귀를 기울인다.</p>

<p>내가 타인과 다름이 주는 쾌감은 스스로에게도 꽤나 크다. 어쩌면 제일 클지도 모른다.</p>

<p>그러나, 희소함이 내 행동의 내적 동기가 될 수 있는가?</p>

<p><br /></p>

<h1 id="rationale">Rationale</h1>

<blockquote>
  <p>Rationale : a set of reasons or a logical basis for a course of action or a particular belief.</p>
</blockquote>

<p>좋은 논문의 서론에서 저자는 ‘이 연구가 왜 novel한지’와 더불어, ‘이 연구가 왜 합당한지’를 이야기한다.</p>

<p>아무도 해보지 않았음은 곧, 검증되지 않았음을 의미하기도 한다. 특히 published된 연구가 없음은, ‘아무도 해보지 않았음’이 아니라 ‘해본 모두가 실패했음’의 가능성도 내재한다.</p>

<p>나의 시도가 기존의 시도들에 비해 뚜렷하게 갖는 이점, 혹은 이점을 기대할만한 논리적 근거가 존재하여 스스로가 설득되었을 때 연구자는 확신을 갖고 어떤 어려움도 밀고 나갈 수 있다. 예상과 다른 결과를 마주했을 때 동력을 잃지 않고 문제를 분석할 수 있다.</p>

<p>실패 가능성이 높은 새로운 연구일수록, rationale을 찾는 시도는 불가결하다.</p>

<p><br /></p>

<h1 id="희소함의-당위">희소함의 당위</h1>

<p>연구와 삶의 다른 점은, 감정이 관여한다는 것이다. 이는 희소함에 대하여 아래와 같은 고민거리를 더한다.</p>

<blockquote>
  <p>첫 번째로, 내가 제시한 새로운 가설이 검증의 과정을 거치기도 전에 ‘새롭다’는 느낌만으로 타인에게 관철되기 쉽다. 제안하는 사람의 사람됨, 표현 방식, 명성, 지위 등이 주는 신뢰감이라는 감정은, 타인에게 ‘어련히 저 사람이 맞겠지’라는 위험한 눈가리개를 씌우고 비판적 검토를 막는다. 영향력 있는 사람의 근거 없는 주장은 그래서 더 위험하다.</p>
</blockquote>

<blockquote>
  <p>두 번째로, 다름은 빠르게 관철될 수 있는 만큼, 역설적으로 너무 쉽게 틀림으로 변질한다. 극소수의 다름은 관철되지 않으면 소외될 수밖에 없다. 이에 수반되는 외로움이라는 감정은, 나의 희소함이 틀렸다는 자기부정과 다수에 속하고자 하는 안정욕구로 이어지기 마련이다. 그렇게 되지 않기 위한 자기확신은 행동의 동력이 타인이 아닌 나에 의해서 정의될 때 가능하다고 생각한다.</p>
</blockquote>

<p>삶의 순간들에서도, rationale을 찾아야 한다. 희소함이라는 도구는 사용하는 것이지, 휘둘리는 것이 아니다.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Thoughts&quot;]" /><category term="에세이" /></entry><entry><title type="html">Contrarian을 응원하며</title><link href="http://localhost:4000/bridges/Contrarian%EC%9D%84-%EC%9D%91%EC%9B%90%ED%95%98%EB%A9%B0/" rel="alternate" type="text/html" title="Contrarian을 응원하며" /><published>2025-05-09T00:00:00+09:00</published><updated>2025-05-09T00:00:00+09:00</updated><id>http://localhost:4000/bridges/Contrarian%EC%9D%84%20%EC%9D%91%EC%9B%90%ED%95%98%EB%A9%B0</id><content type="html" xml:base="http://localhost:4000/bridges/Contrarian%EC%9D%84-%EC%9D%91%EC%9B%90%ED%95%98%EB%A9%B0/"><![CDATA[<hr />

<p class="notice--info">‘가만히 있지 않는다는 것’의 답글입니다.</p>

<h3 id="1">1.</h3>
<ul>
  <li>동물의 제 1 목표는 생존임.</li>
  <li>인간은 체력, 방어력, 감각능력 등 신체 능력은 다른 개체에 비해 열등한 동물임.</li>
  <li>인간은 다른 개체 대비 우월한 사회적 협력과 조직화 능력을 보유하고 있음.</li>
  <li>이로 인해 인간은 불리한 신체 조건에도 불구하고 생태계를 지배하는 유일한 종이 되었음.</li>
  <li>즉, 인간에게 조직은 개인보다 목표 달성을 위한 우월한 구조임.</li>
</ul>

<h3 id="2">2.</h3>
<ul>
  <li>현대 사회에서 생존이라는 본능은 다양한 사회적 목표로 분화됨.</li>
  <li>좋은 조직은 나의 목표와 조직의 목표의 방향이 일치하는 조직임.</li>
  <li>이 경우, 조직을 위하는 것이 곧 나를 위하는 것이 됨.</li>
  <li>그렇지 못한 조직은 개인과 조직에게 모두 들어가지 않는 것이 최선, 빨리 나오는 것이 차선임.</li>
</ul>

<h3 id="3">3.</h3>
<ul>
  <li>관성은 운동 상태의 변화를 거부하는 저항의 성질임.</li>
  <li>조직이 방향을 갖고 움직이기 시작하면 해당 방향을 유지하려는 관성이 형성됨.</li>
  <li>따라서 조직의 방향을 바꾸려면 관성이라는 저항을 이겨내야 함.</li>
</ul>

<h3 id="4">4.</h3>
<ul>
  <li>관성을 줄이는 방법은 질량을 줄이는 것임.</li>
  <li>즉, 기존의 방향에 대한 판단을 유보하거나, 옳다고 믿던 구성원의 수를 줄여야 함.</li>
  <li>따라서 그들에 대한 설득의 과정이 필요할 것임.</li>
</ul>

<h3 id="5">5.</h3>
<ul>
  <li>방향 전환에 대한 설득을 위해서는 조직의 목표가 무엇인지 재정립이 필요함.</li>
  <li>그리고 방향 전환이 조직의 목표를 달성할 수 있는 더 우월한 방법임을 설명할 수 있어야 함.</li>
  <li>즉, 목표 달성 차원에서 기존 방향이 열등한 이유를 설명할 수 있거나, 더 나은 대안을 제시할 수 있어야 함.</li>
  <li>위 2가지가 이루어지지 않은 반박은 무의미하고 해로움.</li>
</ul>

<h3 id="6">6.</h3>
<ul>
  <li>조직에게 무의미하고 해로운 영향은 조직의 목표 달성 확률을 떨어뜨림.</li>
  <li>이는, 나의 목표 달성 확률을 낮추는 일임.</li>
  <li>그러나, 위 2가지가 이루어진 반대의 의견은 조직의 목표 달성 확률을 매우 높임.</li>
  <li>이는, 나의 목표 달성 확률을 높이는 일임.</li>
</ul>

<h3 id="7">7.</h3>
<ul>
  <li>나는 이루고 싶은 목표가 있는가? 나는 조직의 필요성을 인지하고 있는가? 나는 좋은 조직에 속해 있는가?</li>
  <li>그렇다면, 내가 속한 조직은 위와 같은 선순환이 가능한 조직일 것임.</li>
  <li>그렇다면, 내가 속한 조직은 Contrarian이 필요하며, 준비된 반박은 조직과 나를 위하는 일임.</li>
  <li>그렇지 않다면, 가만히 있는 것이 반이라도 갈 수 있는 방법임.</li>
  <li>그러나, 조직의 방향에 동의가 되지 않음에도 가만히 있어야 반을 갈 수 있는 조직에서 목표를 이루는 것은 불가능함.</li>
</ul>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Bridges&quot;]" /><category term="에세이" /></entry><entry><title type="html">Solving Challenges in Multi-modal Contrastive Learning</title><link href="http://localhost:4000/papers/Solving-Challenges-in-Multi-modal-contrastive-learning/" rel="alternate" type="text/html" title="Solving Challenges in Multi-modal Contrastive Learning" /><published>2025-04-19T00:00:00+09:00</published><updated>2025-04-19T00:00:00+09:00</updated><id>http://localhost:4000/papers/Solving%20Challenges%20in%20Multi-modal%20contrastive%20learning</id><content type="html" xml:base="http://localhost:4000/papers/Solving-Challenges-in-Multi-modal-contrastive-learning/"><![CDATA[<hr />

<h1 id="introduction">Introduction</h1>
<p>‘다른 modality’는, 단순히 ‘다른 내용’을 의미하지 않는다. 내용뿐만 아니라 담긴 정보의 수준과 층위가 아예 다르기 때문이다. 가령, ‘예쁜 강아지’라는 글에서의 ‘강아지’가 갖는 해석 가능성이 다양하고 포괄적인 정보와, 강아지 사진에서 ‘강아지’의 확정적인 생김새가 주는 정보를 상상하면 직관적으로 이해가 될 것이다.</p>

<p>따라서, 다른 modality의 정보 사이의 유사성을 비교하는 contrastive learning의 과정에서는 individual modality의 정보가 손실되는 등의, 제대로 align하지 않아 생기는 여러 문제가 존재한다.</p>

<p>이에, CLIP loss가 제안된 이후 multi modal contrastive learning의 문제점들과, 이를 해결하고자 등장한 방법론 3개를 정리하고자 한다. 구체적인 evaluation 과정보다는, 논문의 아이디어를 중심으로 전개하겠다.</p>

<p><br />
<br /></p>

<h1 id="remaining-challenges">Remaining Challenges</h1>

<h2 id="1-heterogeneity-gap">1. Heterogeneity Gap</h2>

<hr />

<p>두 모달리티를 align하는 데에 있어서,  modality의 이질성(heterogenity gap)을 고려해야 한다. 각 모달리티 이질성을 고려하지 않고 형식적인 align을 수행하면, 모델이 일부 중요한 정보를 놓치거나(underalignment), 반대로 중복되거나 무관한 정보를 혼동하게(overalignment) 만들 수 있다. 결과적으로 멀티모달 대조 학습의 근간인 양 modalities 간 semantic support가 약화되어, 최종 표현 학습의 효율이 떨어지게 된다. 두 가지 heterogenity gap을 생각해볼 수 있다.</p>

<h3 id="11-추상화-레벨의-불일치granuality-mismatch"><strong>1.1. 추상화 레벨의 불일치(granuality mismatch)</strong></h3>

<p>멀티모달 데이터에서 서로 다른 modality는 서로 다른 의미/표현 수준의 정보를 전달한다.</p>
<p align="center"><img src="https://github.com/user-attachments/assets/a5163cf8-4d8f-4ae6-ba0e-cfe9d0a0630a" width="600" /><br /><em>이미지와 텍스트의 추상화 레벨 불일치</em></p>

<p>예컨대 오른쪽 강아지 이미지의 경우, 해당 이미지는 “웃고 있는 개”라는 상위 개념뿐만 아니라 품종, 털 색상, 크기, 형태 등 다양한 하위 수준의 속성을 포함하고 있다. 반면, “잔디밭에서 웃고 있는 개”라는 텍스트 설명은 일반적으로 더 추상적이고 압축된 정보만 담고 있다. 이러한 불일치는 멀티모달 대조 학습 과정에서 서로 다른 수준의 의미를 동등하게 맵핑하기 어렵게 만든다. 특히 시각적으로 표현된 하위 속성(예: 털의 질감, 표정 등)이 텍스트 캡션에서 직접 언급되지 않으면, 대응되는 의미를 찾지 못해 학습이 불안정해질 수 있다.</p>

<h3 id="12-구조적-이질성"><strong>1.2. 구조적 이질성</strong></h3>
<p align="center"><img src="https://github.com/user-attachments/assets/bd264feb-149f-47ea-b62f-af6f9798f03a" width="600" /><br /><em>이미지와 텍스트의 처리 방식</em></p>
<p>이미지를 작은 패치 단위로 나누어 특징을 추출하는 방식과, 텍스트를 토큰(단어·문장 등) 단위로 나누는 방식 간에는 불가피한 구조적 차이가 존재한다.</p>

<ul>
  <li>합성곱 신경망(CNN)이나 비전 트랜스포머(ViT)를 통해 처리되는 패치는 픽셀 값의 2D 그리드로 구성되어 있으며, 공간적 관계와 질감 정보를 포함한다.</li>
  <li>텍스트에서 BERT나 GPT와 같은 언어 모델로 처리되는 순차적인 토큰은, 문법적 구조와 의미론적 관계를 포함한다.</li>
</ul>

<p>CLIP(Contrastive Language-Image Pre-training)과 같은 초기 모델들은 이미지와 텍스트를 매칭하여 관계를 학습하나, 이러한 모델들은 시각적 패치와 텍스트 토큰을 집계하여 표현할 뿐, 동일한 세밀도 수준에서 시각적 및 의미적 개념을 명시적으로 정렬하지 않는다. 이를 단순 병렬로 처리하거나 동일 차원으로 맞추는 것만으로는 세밀한 의미 정렬이 보장되지 않는다.</p>

<h2 id="2-결측-모달리티missing-modality-문제">2. 결측 모달리티(Missing Modality) 문제</h2>

<hr />

<p>멀티모달 모델을 응용하는 실제 상황에서는 이미지 또는 텍스트가 일부 누락된 상태로 데이터를 받는 경우가 빈번하게 발생한다. ‘다양한 모달리티’를 복합적으로 고려하여 풍부하고 정확한 해석을 하고자 만든 모델인데, 오히려 모달리티의 다양성이 제약조건을 만들어버리는 것이다. 결측 상황은 단순한 예외적 상황으로 치부해버리기엔 너무나 보편적인 문제이기에, 멀티모달 시스템이 필수적으로 해결해야 하는 과제로 여겨지고 있다.</p>

<p>가령, 아래와 같은 상황이 있을 수 있겠다.</p>

<ul>
  <li>이미지는 있지만 그에 대한 텍스트 태그나 캡션이 없는 경우</li>
  <li>멀티모달 센서 네트워크에서 특정 센서의 일시적 장애로 인한 데이터 결측</li>
  <li>의료 진단 시스템에서 특정 검사 결과의 부재</li>
</ul>

<p><strong>학습 시에는 모든 모달리티 정보를 이용할 수 있으나, 추론 과정에서는 특정 모달리티가 결측되는 현상(train-inference discrepancy)은 모델의 일반화 성능을 크게 저하시킬 수 있다.</strong></p>

<p>“[CVPR 2020] Gradient-Blending: Learning Modalities with Varying Rates”의 내용을 바탕으로 살펴보면, 학습된 모델은 특정 모달리티(특히 많은 정보가 있는 모달리티)에 의존하는 편향을 보일 수 있으며, 이러한 편향은 해당 모달리티가 결측되었을 때 성능이 급격히 저하되는 현상으로 이어진다. 해당 논문에서는 일부 멀티모달 모델은 단일 모달리티 입력 시 성능이 무작위 추측 수준으로 떨어지는 현상을 관찰하였다.</p>

<p><br />
<br /></p>

<h1 id="solving-challenges-in-multi-modal-contrastive-learning">Solving Challenges in Multi-Modal Contrastive Learning</h1>

<p>모달리티별 이질적인 표현을 공유 reprentation space에 정렬하고, missing modality의 문제를 다루는 시도들은 꾸준히 이루어지고 있다. 가령 각 모달리티의 확률 분포를 추정하는 VAE 기반 방법, 이산 표현(코드북)을 사용하는 벡터 양자화(VQ) 기반 접근법 등을 들 수 있겠다. 본 글에서는, <strong>contrastive learning</strong> 으로 학습하는 모델 구조를 큰 틀에서 변경하지 않고, 위 문제들을 해결하고자 시도한 논문 세 편의 방법론을 정리한다. 세 논문 모두 <strong>공통의 latent space에서의 representation align</strong> 을 목표하며, 세번째 논문은 missing modality의 문제를 함께 다룬다.</p>

<h2 id="1-unified-multi-modal-training-intra---inter-modal-similarity-preservation">1. Unified Multi-modal Training (Intra- &amp; Inter-modal Similarity Preservation)</h2>

<hr />

<blockquote>
  <p>[ICML 2022] Multimodal Contrastive Training for Visual Representation Learning</p>

</blockquote>

<p>💡<strong>핵심 아이디어 : 통합 학습 프레임워크(Unified Training Framework):</strong></p>

<ul>
  <li><em>Intra-modal Training Path</em>를 통해 각 모달리티 내에서 data augmentation에 의한 self-supervised 학습을 수행하며, intrinsic data properties를 최대한 보존한다.</li>
  <li><em>Inter-modal Training Scheme</em>를 통해 이미지와 텍스트 등 서로 다른 모달리티 간의 cross-modal interactions를 강화하여, 공통 semantic space 내에서 유사도를 보존하도록 학습한다.</li>
</ul>

<h3 id="11-objective">1.1. Objective</h3>

<p>본 논문에서는, 이미지와 텍스트 데이터를 바탕으로, visual representation을 학습하는 것을 목표한다. 논문에서 강조하는 점은 cross-modal correlation을 배우는 것을 넘어서서 각 modality의 intrinsic data property를 unified framework로 최대한 끌어낸다는 것이다. (저자들은 similarity preservation이라고 표현한다.)</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/39bcfe24-3340-4ba4-939f-d6e7148e6f20" width="600" />
  <br />
  <em>(d)가 논문의 방법으로, 2번/3번과 같은 modality 안 학습과, 4번/5번과 같은 modality 사이 학습을 동시에 진행한다.</em>
</p>

<h3 id="12-method">1.2. Method</h3>
<p align="center">
  <img src="https://github.com/user-attachments/assets/ed297e33-d92b-4819-8140-3999234764da" width="600" />
  <br />
  <em>위 그림에서, 주황색과 초록색이 modality 내 학습을, 노란색과 초록색이 modality 간 학습을 의미하며, 각각 다른 constrasive loss를 사용한다.</em>
</p>

<ol>
  <li>
    <p><strong>Modality 내 학습 : MoCo-v2 framework</strong></p>

    <p>본 논문에서는, modality 내의 unsupervised visual representation learning을 위해 <strong>Momentum Contrast(MoCo)</strong>라는 방법을 차용한다.</p>

    <blockquote>
      <p><strong>Momentum Contrast(MoCo)</strong>
Xinlei Chen, Haoqi Fan, Ross B. Girshick, and Kaiming He. Improved baselines with momentum contrastive learning.</p>
      <p align="center"><img src="https://github.com/user-attachments/assets/d0640ca8-66e2-4fad-a89f-7a5b97be6d09" width="600" /><br /><em>MOCO</em></p>

      <p>이미지는 각 픽셀이 연관되어 있고, 고차원이기에 tokenized word dictionary와 같이 구조화된 dictionary를 만들 수 없다. 따라서 dynamic dictionary (동적사전)가 필요한데, MoCo는 이 사전을 &lt;크고, 안정적으로&gt; 만드는 방법으로 제안되었다.</p>
      <ul>
        <li>key는 데이터(이미지, patch 등)에서 sampling을 한 후 momentum encoder를 통해 표현이 된다.
          <ul>
            <li>‘momentum encoder’이라고 이름붙여진 이유는 다음과 같다.  key를 만들어내는 encoder가 빠르게 학습이 되면 representation이 빠르게 바뀌기 때문에 이전에 dictionary의 key들이 다 소용이 없어지게 된다. 그렇기 때문에 momentum을 이용해 조금씩 변화를 주어서 한번에 큰 변경이 없게 만들어 학습을 안정적으로 진행한다.</li>
          </ul>
        </li>
        <li>query encoder는 momentum encoder과 달리 적극적으로 학습된다. query는 matching 되는 key와 가깝고, 다른 key와는 다르게 constrasive learning이 이루어진다.</li>
      </ul>
    </blockquote>

    <p>저자들은 기존 MoCo에서 text encoder/text momentum encoder를 추가로 도입하고, tag information을 loss에 추가하여 high-level concept의 pattern도 학습하게 하였다.</p>
  </li>
  <li>
    <p><strong>Modality 간 학습 : common space mapping + contrastive learning</strong></p>

    <p>크게 특별할 것 없이, 이미지(CNN 기반)와 캡션(Bert-like transformer 기반)을 각각 <strong>독</strong>립적인 MLP projection head를 통해 공통 공간으로 매핑한 뒤, 양방향 contrastive loss를 설계한다.</p>

    <ul>
      <li>Image-to-Caption: 이미지 표현과 대응하는 캡션 표현의 유사도를 높이고, 나머지 음성 샘플들과의 유사도는 낮춤.</li>
      <li>Caption-to-Image: 캡션 표현과 대응하는 이미지 표현의 유사도를 높이고, 나머지는 낮춤.</li>
    </ul>
  </li>
</ol>

<h2 id="2-finite-discrete-tokens-fdt">2. Finite Discrete Tokens (FDT)</h2>

<hr />

<blockquote>
  <p>[CVPR2023] Revisiting Multimodal Representation in Contrastive Learning: From Patch and Token Embeddings to Finite Discrete Tokens</p>
</blockquote>

<p>💡<strong>핵심 아이디어 : Finite Discrete Tokens (FDT):</strong></p>

<ul>
  <li>학습 가능한 일정 수의 discrete tokens를 사전의 단어들마냥 도입하고, 이미지와 텍스트 모두를 동일한 FDT 집합의 sparse attention-based aggregation으로 표현한다.</li>
  <li>기존 [이미지 패치의 가중합]과 [단어 토큰의 가중합]의 유사도 비교 대신 [FDT의 가중합 1]과 [FDT의 가중합 2]의 유사도 비교를 함으로써
1) FDT라는 같은 granuality에서의 비교
2) 두 모달리티의 진정한 의미론적 비교
를 가능하게 한다.</li>
</ul>

<h3 id="21-objective">2.1. Objective</h3>
<p align="center"><img src="https://github.com/user-attachments/assets/d3e1a253-7590-4858-983d-b7811a7bc1df" width="600" /><br /><em>오른쪽이 논문의 방법이다.</em></p>

<p>저자들은, CLIP 기반 모델에서, cross-modal information을 두개의 독립적 인코더로 인코딩한 뒤 바로 similarity를 비교하는 방식의 한계를 지적한다. 두 representation의 granualities(세밀한 정도)가 다르기 때문이다. 저자들은 같은 level의 granuarity를 가지는 정보 간 contrasive learning을 수행하는 것을 목표한다. 이를 위하여 본 논문은 두 information의 정보들을 각각 FDT라는 공통된 토큰집합을 매개로 표현한 뒤 학습을 수행한다.</p>

<h3 id="22-method">2.2. Method</h3>
<p align="center"><img src="https://github.com/user-attachments/assets/82da74c5-b3bb-4c16-abf9-f16e18538c7e" width="600" /><br /><em>전체 framework(왼), FDT based Feature generation 방법(오)</em></p>

<p>FDT를 이용해서 두 modality의 granuality를 맞추어 contrasive learning을 수행하는 방법은 위 모식과 같다. FDT(Finite Discrete Tokens)는, 왼쪽 가운데에 표현된 노란색 토큰들의 집합이다. 이 토큰들을, 사전의 단어들이라고 생각할 수 있다. Image의 FDT based Feature를 구하는 것은, 결국 이 동적 사전의 단어들의 가중합으로 이미지를 표현하는 것을 의미한다. 방식은 아래와 같다.</p>

<p>a. 먼저, 패치와 FDT 간의 내적 계산으로 N개의 패치가 FDT들과 얼마나 유사한지 나타내는 attention matrix가 구해진다.(오른쪽 가운데 회색 matrix) 이때 각 패치를 query, FDT를 key라고 볼 수 있겠다.</p>

<p>b. Max pooling을 통하여, C개의 FDT 각각이 이미지와 얼마나 유사한지의 유사도를 구한다.</p>

<p>c. FDT의 토큰들을 앞서 구한 유사도를 가중합하여 최종적으로 FDT based Feature를 구한다.</p>

<p>이렇게 구해진 FDT based image Feature, FDT based text Feature간 contrasive learning을 수행한다.</p>

<p>FDT는 각 이미지 패치와, 텍스트 토큰이 의미를 알려주는 prior knowledge의 기능을 수행한다. 이때 유의해야 할 것은, 결국 학습의 궁극적 목적은 text encoder, image encoder가 각각 유의미한 representation을 인코딩하게 학습되는 것이며 FDT는 이를 도와주는 역할이라는 것이다. <strong><em>Text FDT grounding, image FDT grounding 자체가 나중에 쓰이는 건 아니다.</em></strong></p>

<h2 id="3-geometric-multimodal-contrastive-gmc">3. Geometric Multimodal Contrastive (GMC)</h2>

<hr />

<blockquote>
  <p>[ICML 2022] Geometric Multimodal Contrastive Representation Learning</p>
</blockquote>

<p>💡 <strong>핵심 아이디어 : Geometric Multimodal Contrastive Loss</strong></p>

<ul>
  <li>전체 모달리티가 존재하는 <strong>complete observation</strong>과, <strong>결측(modality missing)된 상황의 representation을 서로 가까이 정렬</strong>하도록 기하학적으로 학습하는 novel한 loss를 설계하였다.</li>
</ul>

<h3 id="31-objective">3.1. Objective</h3>
<p align="center"><img src="https://github.com/user-attachments/assets/2ff01865-2532-4fc9-9cce-5a38b4ac5b8d" width="600" /><br /><em>가운데의 Z1:2가 complete modality representation이다.</em></p>

<p>해당 논문은, modality의 종류나 개수를 한정짓지 않는 새로운 프레임워크를 제안한다. 저자들은 <strong>1) modality 간 hetrogenity gap 2) missing modality 문제를 동시에 해결하는 것을 목표</strong>한다.</p>

<p>이를 위하여 모달리티 특이적 encoding만을 진행하는 기존 방법과 달리 모든 모달리티가 통합된 <strong>complete modality representation을  추가로 도입하여, 공통 공간에서 align한다.</strong></p>

<h3 id="32-method">3.2. Method</h3>
<p align="center"><img src="https://github.com/user-attachments/assets/e13866ea-b5dd-4b5a-973a-1c1a1d32d974" width="600" /><br /><em>전체 framework</em></p>

<p><strong>a. Two-level Architecture</strong>
    - <em>Modality-specific Base Encoders</em>를 이용해 각 모달리티와 complete-modality를 고정 차원의 intermediate representation으로 변환한다. (위 그림의 f)
    - 이후, <em>Shared Projection Head</em>를 거쳐 모든 모달리티를 공통의 latent representation space로 매핑한다. (위 그림의 g)</p>

<p><strong>b. Geometric Multimodal Contrastive Learning</strong></p>

<ul>
  <li>contrastive learning은, 위 그림의 공통된 임베딩공간(점선 박스)에서 수행된다.</li>
  <li>각 modality의 표현 $z_m$이 동일한 샘플의 complete representation인 $z_{1:M}$과는 가깝도록(위 그림의 빨강/파랑 실선), 다른 샘플의 표현들과는 멀어지도록(위 그림의 점선) 학습한다.</li>
</ul>

<p>이러한 geometric alignment는, 각 modality가 스스로 complete representation과 의미관계가 가까워지도록 학습하기 때문에, <strong>결측 modality가 존재해도 남은 modality만으로도 충분히 전체 의미를 유추할 수 있는 표현을 생성할 수 있게 된다.</strong></p>

<p>또한, modality의 fusion이 강제되는 기존 방식과 달리, 각 modality가 독립적으로 학습되어 전체 의미공간으로 연결되므로, modality의 종류/개수가 자유롭다는 점도 위 두 논문과의 차이점이다.</p>

<p><br />
<br /></p>

<h1 id="to-sum-up">To sum up…</h1>

<p>본 글에서는 멀티모달 모델에서 modality 간 이질성(heterogeneity gap)과 <strong>결측(modality missing)</strong> 문제에 대응하고자 제안된 세 가지 방법론을 살펴보았다.</p>

<ul>
  <li>첫 번째로 소개한 <strong>Unified Multimodal Training</strong>은 intra-modal과 inter-modal 학습 경로를 동시에 학습하는 통합 프레임워크를 통해, modality별 intrinsic property를 보존하면서도 공통 표현 공간에서의 정렬을 유도한다.</li>
  <li>두 번째 방법인 Finite Discrete Tokens (FDT)는 이미지와 텍스트의 표현 granularity 차이를 해결하고자, 양 modality 모두를 학습 가능한 고정된 토큰 집합(FDT)으로 표현하여 더 정밀한 의미 수준에서의 정렬을 가능하게 한다.</li>
  <li>마지막으로 Geometric Multimodal Contrastive (GMC는 complete modality representation과 partial modality representation 간의 기하학적 정렬을 통해, modality 수나 조합, 결측상황에 구애받지 않는 유연성을 제공한다.</li>
</ul>

<p>이들 방법론은 모두 기존 contrastive learning의 개념을 유지하면서도, align하는 대상과 방법울 다르게 하여 견고한 멀티모달 representation learning을 목표하였다는 점에서 특징적이다.  앞으로의 멀티모달모델이 더욱 다양한 입력 조건과 복잡한 의미 관계를 다루게 될 것을 고려할 때, 이와 같은 새로운 방법론은 더욱 중요한 연구 방향이 될 것으로 기대한다.</p>

<p><a href="https://www.notion.so/1d50175a0e2d8074963efe10e8ab1b6f?pvs=21">정리</a></p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Papers&quot;]" /><category term="Multimodal AI" /><category term="Contrastive Learning" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">명분과 실리</title><link href="http://localhost:4000/thoughts/04.-%EB%AA%85%EB%B6%84%EA%B3%BC-%EC%8B%A4%EB%A6%AC/" rel="alternate" type="text/html" title="명분과 실리" /><published>2025-03-24T00:00:00+09:00</published><updated>2025-03-24T00:00:00+09:00</updated><id>http://localhost:4000/thoughts/04.%20%EB%AA%85%EB%B6%84%EA%B3%BC%20%EC%8B%A4%EB%A6%AC</id><content type="html" xml:base="http://localhost:4000/thoughts/04.-%EB%AA%85%EB%B6%84%EA%B3%BC-%EC%8B%A4%EB%A6%AC/"><![CDATA[<hr />

<p class="notice--info">원칙은 바뀔 수 있음이 원칙이다.</p>

<p>세상의 많은 일에는, ‘어떻게 보여지는가’가 관여하며</p>

<p>가진 것이 많은 사람일수록 이러한 측정 불가능한 가치가 중요해진다.</p>

<p>좋은 지도자는, 강한 자의 명분을 지켜주며 약한 자의 실리를 추구해야 한다.s</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Thoughts&quot;]" /><category term="에세이" /></entry><entry><title type="html">가만히 있지 않는다는 것</title><link href="http://localhost:4000/thoughts/03.-%EA%B0%80%EB%A7%8C%ED%9E%88-%EC%9E%88%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8B%A4%EB%8A%94-%EA%B2%83/" rel="alternate" type="text/html" title="가만히 있지 않는다는 것" /><published>2025-03-23T00:00:00+09:00</published><updated>2025-03-23T00:00:00+09:00</updated><id>http://localhost:4000/thoughts/03.%20%EA%B0%80%EB%A7%8C%ED%9E%88%20%EC%9E%88%EC%A7%80%20%EC%95%8A%EB%8A%94%EB%8B%A4%EB%8A%94%20%EA%B2%83</id><content type="html" xml:base="http://localhost:4000/thoughts/03.-%EA%B0%80%EB%A7%8C%ED%9E%88-%EC%9E%88%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8B%A4%EB%8A%94-%EA%B2%83/"><![CDATA[<hr />

<p class="notice--info">원칙은 바뀔 수 있음이 원칙이다.</p>

<h1 id="introduction--가만히-있으면-반이라도-간다">Introduction : 가만히 있으면 반이라도 간다.</h1>

<p>가만히 있는 것은 실로 매력적인 선택지이다. 오죽하면 ‘가만히 있으면 반이라도 간다.’, ‘말할까 말까 할 때는 말하지 말라’라는 이야기가 나왔겠는가.</p>

<p>나의 ‘가만히 있지 않음’에 타인과의 상호작용이 관여할 때 고려해야 할 것들은 더 많아진다.</p>

<p>절대적인 선과 악이 없는 모호한 세상에서, 나의 선이 누군가에게는 악이 될 수 있으며
내가 가벼이 여긴 타인의 이야기가 당사자에게는 다른 무게와 깊이일 수 있다.</p>

<p>가만히 있지 않는다는 것은 곧 그 시점의 나의 일부를 타인에게 표현하는 일이기에 누군가는 그 일부로써 나를 정의할 것이다.</p>

<p>그러나 이 많은 머리아픈 일들을 감수하며 말하고 행동할 때, 세상은 움직이고 관계는 변화한다.</p>

<p><br /></p>

<h1 id="반은-가겠지만-가는-방향을-바꿀-수-없다">반은 가겠지만, 가는 방향을 바꿀 수 없다.</h1>

<p>가만히 있음은 멈춤을 의미하지 않는다. 이 잠깐 사이에도 지구가 도는 속도로 돌고 있는 것처럼, 세상의 많은 흐름들에 속하는 우리는 그 흐름대로 끊임없이 가는 중이다.</p>

<p>같은 방향으로 흐르는 주변인들과 관계를 맺고 마음을 나누기에, 집단 속에서 가만히 집단의 방향대로 흐르는 것은 더욱 안정적이다.</p>

<p>그러나 누군가는 이 흐름의 키를 잡고 있겠지, 맞는 방향으로 조정하고 있겠지, 하는 생각이 안일한 안주였음은 보통 무작정 흐르다 도착한 벼랑의 끝에서 드러난다.</p>

<p>집단의 방향을 바꾸는 것에는 세 번의 큰 노력이 필요하다. 당장의 안정감에서 벗어나 ‘이 방향이 맞아?’라는 의구심을 가지는 것에 한 번, 또 이 의구심을 대책과 함께 세심하게 제시하는 것에 한 번, 마지막으로 내가 바꾼 방향이 향하는 곳을 끝까지 살피는 것에 한 번.</p>

<p>모든 과정이 쉽지 않지만, 특히 세번째 과정이 수반하는 책임감이 어마어마하다고 생각하였다. 예측 불가능한 결과를 책임져야 한다는 부담은, 때로는 의구심을 제기하는 대신 아예 집단에 속하지 않는 것을 선택하게 만들었다.</p>

<p>그러나 예측 불가능함은 곧, 생각하지 못한 더 좋은 방향으로 나아갈 가능성을 의미하기도 한다. 건강한 토의가 서로의 불완전한 생각을 보완한다.</p>

<p>소중한 내 주변인이 나의 서툶을 보듬어줄 이들임을 신뢰하고자 한다. 그렇기에 가만히 있지 않고 ‘이 방향이 맞아?’라고 용기내어 말해보고자 한다.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Thoughts&quot;]" /><category term="에세이" /></entry><entry><title type="html">타인에 관하여</title><link href="http://localhost:4000/thoughts/02.-%ED%83%80%EC%9D%B8%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC/" rel="alternate" type="text/html" title="타인에 관하여" /><published>2025-02-22T00:00:00+09:00</published><updated>2025-02-22T00:00:00+09:00</updated><id>http://localhost:4000/thoughts/02.%20%ED%83%80%EC%9D%B8%EC%97%90%20%EA%B4%80%ED%95%98%EC%97%AC</id><content type="html" xml:base="http://localhost:4000/thoughts/02.-%ED%83%80%EC%9D%B8%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC/"><![CDATA[<hr />

<p class="notice--info">원칙은 바뀔 수 있음이 원칙이다.</p>

<h1 id="introduction--우리는-모두-다르지만">Introduction : 우리는 모두 다르지만</h1>

<p>타인을 아는 것은 불가능하다. 설령 같은 경험을 하고 같은 세상을 보더라도, 우리는 다르게 느끼고 다르게 생각한다. ‘나라면 이렇게 할텐데’하며 실망하지 않고, 내가 감히 알 수 없는 감정의 크기를 함부로 재지 않고, 온전히 존중하는 것은 다른 사람이 나와 다르다는 것을 앎에서 시작한다.</p>

<p>상대를 예단하지 않겠다고 생각했다. 또한 조금 타인을 덜 신경써도 되겠다고 생각했다. 어차피 내가 알 수 없는 영역이니, 최소한의 사회적으로 통용되는 도리를 지키며 그 외적인 것들은 조금 더 마음 편하게 해도 되겠구나 싶었다.</p>

<p>그러나 일련의 경험들을 통해 서로를 온전히 알 수 없다고 하더라도, 알아가려는 노력의 가치가 없어지는 것이 아님을 깨달았다. 타인에 대하여, 함께 사는 세상에 대하여 생각을 정리한다.</p>

<p><br /></p>

<h1 id="함께-사는-세상">함께 사는 세상</h1>

<p>주변의 누군가에게 따스함을 느끼는 경험을 많이 하는 요즈음이다. 나의 행복은 나의 안녕에서 비롯하는 줄 알았는데, 누군가의 말 한마디가, 관심과 웃음이, 세심한 배려가, 공유하는 이야기가 가져다주는 행복을 경험하니, 나 또한 이런 따뜻함을 주는 사람이 되고 싶다는 생각이 들었다.</p>

<p>말하기 부담일 수 있는 것들은 먼저 묻지 않는 것,</p>

<p>상대가 공감하기 어려운 이야기를 화두로 올리지 않는 것,</p>

<p>누군가가 사준 음식을 맛있게 먹는 것,</p>

<p>먼저 밝게 인사하고 안부을 묻는 것,</p>

<p>친구의 연락에 답장을 미루지 않고 좋아함을 표현하는 것,</p>

<p>고마운 일에 고맙다고 이야기하는 것,</p>

<p>상대가 ‘갚아야겠다’는 부담을 느끼지 않도록 선을 넘지 않으며 은은하게 배려하는 것.</p>

<p>상대방이 조금 더 행복하지 않을까 고민하고 상상하는 과정이 내게도 행복을 줌을 알았다.</p>

<p>그러나 배려는 ‘상대방은 이럴 거야’라고 생각함으로써 이루어지는, 타자성에 반하는 행위이기도 하다. 그렇기에 아래의 것들을 더욱 주의하고자 한다.</p>

<h2 id="1-배려의-목적은-상대의-안녕이다">1. 배려의 목적은 상대의 안녕이다.</h2>

<p>세심한 누군가에게 내가 좋은 사람으로 보이길 바라며 배려를 행하는 것은, 자기포장에 불과하다. 나를 포장하는 일도 분명 때때로 필요하며, 나를 표현하는 도구가 될 수 있다. 그러나 다른 사람에게 어떻게 보일지를 고려하게 되는 순간, 상대의 안녕보다는 보이는 나의 모습이 더 중요해지며 본래의 가치를 온전하게 느끼지 못하게 되더라.</p>

<p>또한, 나의 배려는 오직 나의 판단에서 비롯했기에, 상대에게는 고마워할 의무도 비슷한 배려를 해야 할 책임도 없다. 오히려 나의 배려가 상대에게 부담이 되었거나, 예상하지 못한 안좋은 영향을 미친 것은 아닌지 살펴야 하는 책임은 나에게 있다. 상대방이 고마워하고 알아주길 바라며 행하는 행동은 나도, 상대도 힘들게 만들 뿐이다.</p>

<p>나의 행동으로 누군가가 안녕해진다면, 그것으로 충분하다. 원래의 목적을 잃은 배려는 상대를 위한 것이 아니다.</p>

<h2 id="2-모든-것에-앞서서-나를-잃지-말아야-한다">2. 모든 것에 앞서서, 나를 잃지 말아야 한다.</h2>

<p>나를 잃으면서까지 누군가를 배려한다면, 어쩔 수 없이 내가 내어준 것이 크게 보이기 마련이다. 
대가 없이 상대의 안녕을 바랄 수 있는 예쁜 마음은, 내가 줄 수 있는 단단함을 갖추었을 때 생기더라.</p>

<p>다른 사람을 안을 수 있는 품을 갖춘 사람이 되고 싶다.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;Thoughts&quot;]" /><category term="에세이" /></entry><entry><title type="html">[KAIST_WURF]0124 카이스트 이정석 교수님</title><link href="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EC%9D%B4%EC%A0%95%EC%84%9D%EA%B5%90%EC%88%98%EB%8B%98/" rel="alternate" type="text/html" title="[KAIST_WURF]0124 카이스트 이정석 교수님" /><published>2025-01-24T00:00:00+09:00</published><updated>2025-01-24T00:00:00+09:00</updated><id>http://localhost:4000/kaist_wurf/KAIST_WURF_%08%EC%98%A4%EC%A0%84_%EC%9D%B4%EC%A0%95%EC%84%9D%EA%B5%90%EC%88%98%EB%8B%98</id><content type="html" xml:base="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EC%9D%B4%EC%A0%95%EC%84%9D%EA%B5%90%EC%88%98%EB%8B%98/"><![CDATA[<p class="notice--info">카이스트 이정석 교수님의 WURF meet the professor 강연을 정리하였습니다.</p>
<h1 id="introduction">Introduction</h1>

<p>본 세션은 <strong>이노크라스(Inocras Inc.) / Genome Insight</strong> 공동창업자가 SK 최종현 학술원 유튜브 강연에서 발표한 ‘유전체 데이터 바이오헬스 AI를 위한 인프라’ 내용을 요약·정리한 것이라고 말씀하셨다. 핵심 메시지는 <strong>유전체 데이터가 곧 디지털 자산</strong>이며, 이를 빠르고 정확하게 해석할 <strong>AI 인프라 구축</strong>이 국가 경쟁력의 관건이 된다는 점이다.</p>

<h2 id="이정석-교수님">이정석 교수님</h2>
<ul>
  <li><strong>공동창업자, Project Stargate 리드</strong><br />
(Inocras Inc. / Genome Insight)</li>
  <li>데이터 규모: 사내 <strong>WGS 데이터 10 PB</strong> 이상 보유</li>
  <li>발표 영상: <em>SK 최종현 학술원</em> YouTube 채널</li>
</ul>

<hr />

<h1 id="1-projectstargate--why-genome-analysts-will-matter">1. Project Stargate — Why Genome Analysts Will Matter</h1>

<table>
  <thead>
    <tr>
      <th> Key Point </th>
      <th> Detail </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>미래 수요</strong></td>
      <td>유전체 데이터를 이해·해석할 전문가는 폭발적으로 필요해질 전망</td>
    </tr>
    <tr>
      <td><strong>Mission</strong></td>
      <td>방대한 서열 정보를 <em>분석 → 임상·산업 가치</em>로 전환</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>“시퀀싱 원가 하락으로 <strong>데이터 생산 독점</strong>은 끝났다. 이제 <strong>해석의 시대</strong>다.”</p>
</blockquote>

<hr />

<h1 id="2-genomedigitaldata">2. Genome = Digital Data</h1>

<table>
  <thead>
    <tr>
      <th> 항목 </th>
      <th> 규모 </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>인간 게놈 길이</strong></td>
      <td>≈3 Gb (30억 bp)</td>
    </tr>
    <tr>
      <td><strong>WGS Raw Reads</strong></td>
      <td>30× 커버리지 → ~90 GB/sample</td>
    </tr>
  </tbody>
</table>

<ol>
  <li><strong>방대하지만 유한(Limited yet Huge)</strong>: 저장·계산 인프라로 관리 가능</li>
  <li><strong>완전한 디지털 정보</strong>: 4진법(ATCG) → 컴퓨팅 친화적</li>
</ol>

<h2 id="varianttypes">Variant Types</h2>
<ul>
  <li><strong>Germline Variants</strong>: 희귀질환, 가족성 암, 만성질환 예측</li>
  <li><strong>Somatic Mutations</strong>: 암 발생·진행, 항암제 감수성, 노화 연관</li>
</ul>

<blockquote>
  <p>암은 세포분열 누적 변이 ∝ <em>Age</em> — 정밀한 변이 지도 필요.</p>
</blockquote>

<hr />

<h1 id="3-precisionmedicine--유전체ai">3. Precision Medicine &amp; 유전체 AI</h1>

<table>
  <thead>
    <tr>
      <th> 기존 의학 </th>
      <th> 정밀의료 </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Evidence‑Based</strong> (집단 평균)</td>
      <td><strong>Individualized</strong> (개인 차이)</td>
    </tr>
    <tr>
      <td>효과·부작용 편차 ↑</td>
      <td>안전성·효용 ↑</td>
    </tr>
    <tr>
      <td>비용 낭비 가능</td>
      <td>예산 효율, 신약 개발 가속</td>
    </tr>
  </tbody>
</table>

<h2 id="기술변곡점">기술 변곡점</h2>
<ul>
  <li><strong>시퀀싱 단가 급락</strong> → 누구나 데이터 생산 가능</li>
  <li><strong>AI + Genome</strong> → 패턴 추출·임상 연계 속도 혁신</li>
</ul>

<hr />

<h1 id="4-targetedcancertherapy--wgs시대">4. Targeted Cancer Therapy — WGS 시대</h1>

<h2 id="패널엑솜wholegenome">패널 → 엑솜 → Whole Genome</h2>
<ol>
  <li><strong>Sequencing Cost</strong> 여전히 부담</li>
  <li><strong>데이터 분석</strong> 병목 (10 PB 규모 관리·해석)</li>
</ol>

<h2 id="clinical-example">Clinical Example</h2>
<ul>
  <li><strong>HER2 증폭</strong>
    <ul>
      <li><em>Focal amplification</em> vs <em>Broad amplification</em> → 치료 전략 달라짐</li>
      <li>WGS로만 후자 정의 가능</li>
    </ul>
  </li>
  <li><strong>림프종 재정의</strong>: 기존 8개 subtype → 세분화된 분자 분류</li>
</ul>

<hr />

<h1 id="5-global-landscape--were-near-the-end-of-data-landgrab">5. Global Landscape — We’re Near the End of Data Land‑Grab</h1>

<ul>
  <li><strong>Exome Megaprojects</strong> (e.g., Regeneron) → 전 세계 <strong>인간 엑솜</strong> 수백만 건 확보 경쟁</li>
  <li>이후 경쟁력은 <strong>데이터 해석·활용 소프트파워</strong>로 이동</li>
</ul>

<h2 id="대한민국의-기회">대한민국의 기회</h2>
<ol>
  <li><strong>의료 데이터 탄탄</strong>: 대형 병원 EMR + WGS 코호트 구축 진행</li>
  <li><strong>융합 인재</strong>: 의사·과학자의 AI 역량 상승 중</li>
  <li><strong>필요 투자</strong>: 대용량 <strong>데이터 파이프라인 &amp; 해석 알고리즘 인프라</strong></li>
</ol>

<blockquote>
  <p>“실험 자동화(로봇)는 표준화될 것. <em>의미 해석</em>이 승부처.”</p>
</blockquote>

<hr />

<h1 id="key-takeaways">Key Takeaways</h1>

<ol>
  <li><strong>Genome Data = 디지털 자원</strong>: 저장·컴퓨팅 인프라가 핵심.</li>
  <li><strong>WGS → 임상 통합</strong>: 암·희귀질환 정밀 진단이 가속화될 것.</li>
  <li><strong>데이터 해석</strong>이 새로운 경쟁력: 하드웨어가 아닌 <strong>알고리즘·소프트파워</strong>.</li>
  <li><strong>한국</strong>은 의료 데이터·인재 풀을 바탕으로 <strong>글로벌 허브</strong>가 될 잠재력.</li>
  <li>인프라 구축과 AI 역량 확보에 <strong>지금 투자</strong>해야 한다.</li>
</ol>

<hr />]]></content><author><name>DaRe_jin</name></author><category term="[&quot;KAIST_WURF&quot;]" /><category term="일지" /></entry><entry><title type="html">[KAIST_WURF]0120 카이스트 김하일 교수님</title><link href="http://localhost:4000/kaist_wurf/KAIST_WURF_%EC%98%A4%EC%A0%84_%EA%B9%80%ED%95%98%EC%9D%BC%EA%B5%90%EC%88%98%EB%8B%98/" rel="alternate" type="text/html" title="[KAIST_WURF]0120 카이스트 김하일 교수님" /><published>2025-01-20T00:00:00+09:00</published><updated>2025-01-20T00:00:00+09:00</updated><id>http://localhost:4000/kaist_wurf/KAIST_WURF_%EC%98%A4%EC%A0%84_%EA%B9%80%ED%95%98%EC%9D%BC%EA%B5%90%EC%88%98%EB%8B%98</id><content type="html" xml:base="http://localhost:4000/kaist_wurf/KAIST_WURF_%EC%98%A4%EC%A0%84_%EA%B9%80%ED%95%98%EC%9D%BC%EA%B5%90%EC%88%98%EB%8B%98/"><![CDATA[<p class="notice--info">김하일 교수님의 ‘의과학의 현재와 미래 의사과학자 양성’을 주제로 한 강연을 정리하였다. 지난 6월까지 학과장이셨다!</p>

<h1 id="introduction">Introduction</h1>
<blockquote>
  <p>나는 누구인가?
들어보고 혹하는 연구는, 사기일 가능성이 농후하다…!
교수님의 연구를 설명해주시기보다, 교수님의 이야기를 해주시고 싶으시다.</p>
</blockquote>

<h2 id="나는-어디로-가고-있는가">나는 어디로 가고 있는가?</h2>
<p>처음부터 과학자가 되고 싶었던 것은 아니다. 재미있어서 어찌저찌 하다보니 이 길을 걷게 되었다. 연구를 하는 가장 저면의 욕구는 재미있기 때문이다.
의대(안맞았다) &gt; molecular biology &gt; 모교에서 3년 교수하시다, 미국으로 가 post doc(mouse로 당뇨병 연구)&gt; 당뇨병 환자들에게 도움이 되는 연구를 하겠다, 논문을 쓰기 위한 연구를 하지 않겠다 &gt; 2016년부터 computational biology를 도입하여, 과거의 tool로 보지 못했던 것을 보게 되었다</p>

<p>나이가 들면 진폭이 점점 좁아지며, 평생동안 할 수 있는 일의 방향성을 찾게 된다. 나는 우연히 이 일을 하게 되었는데, 이 길이 교수님께 맞아서 행복한 삶을 살고 있다.
운이 좋아서, 아등바등 안해도 연구를 하고 논문이 나오는 삶을 살았다.</p>

<h2 id="교수님의-성장과정에서-만난-사람들">교수님의 성장과정에서 만난 사람들</h2>
<ul>
  <li>의과학대학원을 처음 만드신 허갑범 담임반 교수님, 논문을 쓰는 게 중요한 게 아니라 얼마나 환자를 생각하는지가 중요함</li>
  <li>카이스트 이정호교수, 주영석교수 : 생물정보학이 필요함을 꺠달음, 젊은 사람들을 support해야겠다</li>
  <li>살아가면서 여러 사람을 만나는데, 누가 어떤 영향을 줄지 모른다. 사람을 많이 만나야 한다.</li>
</ul>

<h2 id="과학이란">과학이란</h2>
<blockquote>
  <p>방금 당신을 그리는 데 걸린 시간은 단 몇분밖에 되지 않았지만, 당신을 이렇게 그릴 수 있게 되기까지 40년이 걸렸습니다.</p>
</blockquote>

<p>과학은, 당연한 사실을, 있지만 꺠닫지 못하는 것을 찾고 증명해내는 것.
오랫동안 훈련된 직관(너는 남자이다)을 증명하는 것, 내가 무엇을 모르는지 아는 것이다.</p>

<h1 id="정리">정리</h1>
<p>교수님께서는 지방간이 병임을 증명하는 연구를 하고 계신다. 지방간 &gt; 간경화 &gt; 간암이 되는 과정에 초점을 맞추어, 대사성 질환을 진단받기 전에 어떤 pre-disease의 과정을 거치는지에 관심이 있으시다고 한다. 
강연 전반에 거쳐서 교수님의 연구에 관한 학문적 이야기보다는, 삶을 살아가는 태도에 대한 이야기를 주로 하셨다. 어떤 길을 걸어갈 것인지 생각하고 고민하는 것은 중요하나, 내일을 위해 오늘을 쓰지는 말라고 말씀하셨다. 또한 정답이 없는 세상에서 생각을 말하는 것을 겁먹지 말라고 말씀하셨다.
공감이 가는 말씀들이 많았다. 미래에 대해서 그리고 내 선택에 대해서 고민이 많은 요즈음, 어떤 선택을 하더라도, 그 선택을 하는 과정이 잘 쌓인다면 결과가 어떻든 헤쳐나갈 수 있을 것이라는 말씀이 잔잔한 위로가 되었다.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;KAIST_WURF&quot;]" /><category term="일지" /></entry><entry><title type="html">[KAIST_WURF]0116 카이스트 구태윤 교수님</title><link href="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EA%B5%AC%ED%83%9C%EC%9C%A4%EA%B5%90%EC%88%98%EB%8B%98/" rel="alternate" type="text/html" title="[KAIST_WURF]0116 카이스트 구태윤 교수님" /><published>2025-01-16T00:00:00+09:00</published><updated>2025-01-16T00:00:00+09:00</updated><id>http://localhost:4000/kaist_wurf/KAIST_WURF_%08%EC%98%A4%EC%A0%84_%EA%B5%AC%ED%83%9C%EC%9C%A4%EA%B5%90%EC%88%98%EB%8B%98</id><content type="html" xml:base="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EA%B5%AC%ED%83%9C%EC%9C%A4%EA%B5%90%EC%88%98%EB%8B%98/"><![CDATA[<hr />
<p class="notice--info">카이스트 구태윤 교수님의 WURF meet the professor 강연을 정리하였습니다.</p>
<hr />

<h1 id="introduction">Introduction</h1>
<blockquote>
  <p>연구 분야는 급작스럽게 바뀔 수도, 바꿀 수도 있지만 어떤 연구자가 될 것인지는 오랜 시간에 걸쳐서 스스로 만들어나가는 것이다.</p>
</blockquote>

<h2 id="어떤-연구를-해야-하는가"><span style="font-size:90%">어떤 연구를 해야 하는가</span></h2>
<p>연구는 크게 세 가지 종류가 있다.</p>
<ul>
  <li>‘이건 조금만 기다리면 나오겠네, 누군가 하고 있겠네’</li>
  <li>‘세상 사람들보다 내가 먼저 하겠네’</li>
  <li>‘이건 내가 안하면 아무도 안하겠네’</li>
</ul>

<p>이중 교수님께서는 세번째 방향의 연구를 추구한다고 하셨다. 또한, 의학과 의과학의 background가 되는 <strong>‘생명공학기술(연구방법론)’</strong>을 연구함으로써 새로운 연구의 패러다임을 만드는 것을 목표하신다.
<br />
<br /></p>

<h1 id="1-expansion-microscopy">1. Expansion microscopy</h1>

<p>현미경 해상도의 한계를 넘어서는 세포 구조
일반적으로 200um 정도의 해상도인 광학현미경으로는 대부분의 세포 구조를 관찰할 수 없다. 영상기법(하드웨어)는 꾸준히 발전하고 있으나, 미세한 세포구조를 관찰하는 것은 여전히 요원하다.</p>
<blockquote>
  <p>일반적으로는 더 강력한 현미경(또는 영상 장비)을 개발함으로써 해상도를 높이려 노력한다. <strong>영상 기법(하드웨어)의 발전을 기다리지 말고, 잘 관찰할 수 있는 샘플을 만드는 것은 어떨까?</strong></p>
</blockquote>

<p>‘관찰 방법’이 아닌, ‘관찰 대상’을 바꾸자는 아이디어에서 출발한 것이 <strong>Expansion microscopy(ExM)</strong>이다.</p>

<p><strong>Expansion Microscopy(ExM)</strong>는 2015년 MIT의 Edward S. Boyden 연구실에서 처음 발표한 혁신적인 개념이다. 보통 광학 현미경의 해상도는 ~200nm 수준으로, 이보다 더 작은 세포 구조나 분자를 볼 수 없다는 물리적 제약(회절 한계)이 존재한다.
ExM은 이 한계를 <strong>‘샘플을 확장(expansion)해서, 기존 현미경으로도 미세 구조를 관찰 가능하게 만든다’</strong>는 발상의 전환으로 극복한다.</p>

<h2 id="map-기술2세대-초고해상도-현미경--magnified-analysis-of-proteome-technology"><span style="font-size:90%">MAP 기술(2세대 초고해상도 현미경) : Magnified analysis of proteome technology</span></h2>

<p>ExM의 계보를 잇는 2세대 초고해상도 현미경 샘플 처리 기술 중 하나로, 조직에 하이드로젤 모노머를 주입하고, 고정·중합 과정을 거친 후 <strong>물에 넣어 ‘확장’</strong>함으로써 세포 내 단백질이나 분자의 위치 정보를 고해상도로 확인할 수 있게 한다.
하이드로젤 폴리머 구조가 음이온을 띠고, 물이 투입되면서 양이온이 빠져나가 음이온 간 척력으로 샘플이 팽창하는 원리를 이용한다.
<br />
<br /></p>

<h1 id="2-투명-뇌-기술--조직-투명화tissue-clearing">2. 투명 뇌 기술 : 조직 투명화(tissue clearing)</h1>
<h2 id="tissue-clearing"><span style="font-size:90%">Tissue Clearing</span></h2>

<p>조직은 대부분 빛을 산란·흡수하는 성분(지질, 단백질 등)으로 이루어져 있다. 그러다 보니 시료가 두꺼울수록 빛이 내부로 잘 통과하지 못해, 심부 구조를 관찰하기 어렵다. 조직 투명화(Tissue Clearing) 기법은 이런 문제를 해결하기 위해 고안되었다. 조직 투명화 기법은, 아래 세 가지의 방식으로 심부 구조를 관찰하기 어려운 문제를 해결한다.</p>
<ul>
  <li>빛이 산란되어서(랜덤하게 꺾여서) 깊이/투과도가 깊어질수록 관찰이 어려움. =&gt; 산란시키는 물질을 제거(지질 추출)</li>
  <li>빛이 굴절되어서(빛이 미세하게 꺾여서) 초점/선명도가 낮아짐. =&gt; 굴절률 균일화 (투명화 용액)</li>
  <li>
    <p>조직 시료에서 ‘contrast’를 만들어야 관찰을 할 수 있다.</p>

    <p>=&gt; option 1 : 유전자 조작을 통한 형광 단백질 발현</p>

    <p>=&gt; option 2 : 염색 (항체 염색)</p>
  </li>
</ul>

<h2 id="투명화-분야의-난제"><span style="font-size:90%">투명화 분야의 난제</span></h2>

<ol>
  <li>두꺼운 시료의 항체 염색이 어려움 =&gt; 항체와 같은 고분자가 염색될 수 있도록 재질의 낮은 밀도(큰 공극)이 필요함.</li>
  <li>기계적 안정성(투명화시키는 과정에서 쉽게 망가짐) =&gt; 기계적 스트레스에 대한 저항성이 필요함</li>
</ol>

<blockquote>
  <p><strong>‘조직 탄성화’</strong>가 해결할 수 있지 않을까? : 질기고 잡아당겨지는 entagled hydrogel을 이용한다!</p>
</blockquote>

<h2 id="elast조직-탄성화-기반-혁신-기술"><span style="font-size:90%">ELAST(조직 탄성화 기반 혁신 기술)</span></h2>

<ol>
  <li>잘 으깨지지 않아, 큰 인체 조직 시료의 탄성화가 가능하게 한다</li>
  <li>항체 시약을 조직 속에 전달하는 데에 걸리는 시간을 줄이기 위하여
    <ul>
      <li>전하를 띄게 하거나, 항체를 작게 하거나, 소용돌이를 일으키거나…의 기존 기술 대신,</li>
      <li><strong>두께가 줄어들면 염색 시간이 줄어든다</strong>는 가장 기본적인 생각으로 돌아가, 탄성화 조직을 일시적으로 얇게 만들어서, 초고속으로 염색할 수 있다!</li>
    </ul>
    <ul>
      <li>늘리고 고정하고(stretch) 물을 condense시켜 가로세로의 길이는 유지된 채 두께를 혁신적으로 얇게 만든다.
<br />
<br /></li>
    </ul>
  </li>
</ol>

<h1 id="3-공간오믹스spatial-omics의-신기술-개발">3. 공간오믹스(spatial-omics)의 신기술 개발</h1>
<hr />
<p>조직이나 세포를 단순히 ‘형태적 구조’만 보는 것을 넘어, 그 공간적 위치에서 어떤 분자적·생물학적 기능을 수행하는지를 함께 파악하려는 노력은 점차 활발해지고 있다. 이를 <strong>‘공간 오믹스(spatial-omics)’</strong>라 부르며, 크게 세 가지 축으로 나눌 수 있다.</p>
<ol>
  <li>Connectomics(신경망 지도화)</li>
  <li>Spatial transcriptomics(유전자 발현 지도화)</li>
  <li>Functional radiomics(기능적 영상화 기반 대사·활성 연구)</li>
</ol>

<h2 id="connectome완전한-신경망-정보--뇌가-가지는-궁극의-정보는-망네트워크이다"><span style="font-size:90%">Connectome(완전한 신경망 정보) : 뇌가 가지는 궁극의 정보는 망(네트워크)이다</span></h2>

<ul>
  <li>뇌는 네트워크(연결)의 집합체이다. 뉴런 간 연결 전체를 관찰하고 분석하면, 뇌 기능과 의식을 해석하는 핵심 정보를 얻을 수 있다.</li>
  <li>현재까지 완전한 Connectome이 구축된 생물은 선충(2종), 그리고 2024년에 완성된 초파리, 총 3종이 유일하다.</li>
  <li>마우스 뇌의 connectome 전체를 전자현미경으로만 해독하려면 시간(최소 1000년 이상)과 막대한 자원이 필요하다. 이 때문에 전 세계 여러 연구소가 컨소시엄 형태로 도전하고 있다.</li>
</ul>

<h3 id="opto-connectomics-kaisr-ibil"><span style="font-size:90%">Opto-connectomics @KAISR iBIL</span></h3>

<p>목표: 약 1개월 정도의 기간 내에, 개별 연구실 규모에서도 마우스 뇌의 신경망을 해독할 수 있는 기술 개발을 목표로 하고 계시다. 신경망을 전자현미경으로 해독하는 기존 기술의 패러다임을 바꾸는 것!
가능해진다면 뇌 조직 전체가 <strong>‘tissue 샘플’</strong>이 아닌 <strong>‘connectomic data’</strong>로 전환되어, 뇌 과학 연구의 양상 자체가 바뀔 수 있다.</p>

<h2 id="다기능-정밀의료영상-원천기술-개발"><span style="font-size:90%">다기능 정밀의료영상 원천기술 개발</span></h2>

<p>단순한 해부학적 구조(해상도) 파악에 그치지 않고, 대사 과정, 에너지 공급, 세포 기능 등 뇌(또는 다른 조직)의 ‘기능적 면모’를 정밀하게 관찰할 수 있는 영상화 기술.</p>
<ul>
  <li>예: 혈류 유입률, 유출률, 에너지 변환 효율, 산소 교환 능력, 분자 차원의 반응 속도 등.</li>
</ul>

<p>이러한 고차원 영상 데이터를 바탕으로, 개인 맞춤형 진단·치료가 가능한 정밀 의료로의 발전이 기대된다.
<br />
<br /></p>

<h1 id="4-additional-comments">4. Additional Comments</h1>
<hr />
<p>구태윤 교수님께서는 기존의 기술을 담습하지 않고 새로운 생각을 도입하여, 생명과학연구의 근본이 되는 ‘연구방법’ 자체를 바꾸는 연구를 목표하신다고 말씀하셨다. 
대부분의 task를 사람보다 컴퓨터가 더 잘하는 시대에, 우리는 어떤 존재가 되어야 하는지 고민하였을 때, 있는 데이터를 학습하여 성능을 내는 인공지능과 다른 우리의 가장 큰 특징은 <strong>없던 생각을 해내는 능력</strong>이라고 생각한다. 그리고 연구는 내가 가진 창발적 생각을 비약, 회유, 속임 없이 세상에 설득하는 가장 정직한 방법이라고 생각한다.</p>

<p>끊임없이 질문을 던지고, 없던 생각을 하는 삶을 살고 싶다. 그 과정에서 사람을 사랑하는 마음과, 내 분야에 대한 깊이 있는 지식이 합쳐진다면, 언젠가 내 생각이 선한 가치를 만들어낼 수 있지 않을까.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;KAIST_WURF&quot;]" /><category term="일지" /></entry><entry><title type="html">[KAIST_WURF]0114 카이스트 손창호 교수님</title><link href="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EC%86%90%EC%B0%BD%ED%98%B8%EA%B5%90%EC%88%98%EB%8B%98/" rel="alternate" type="text/html" title="[KAIST_WURF]0114 카이스트 손창호 교수님" /><published>2025-01-13T00:00:00+09:00</published><updated>2025-01-14T00:00:00+09:00</updated><id>http://localhost:4000/kaist_wurf/KAIST_WURF_%08%EC%98%A4%EC%A0%84_%EC%86%90%EC%B0%BD%ED%98%B8%EA%B5%90%EC%88%98%EB%8B%98</id><content type="html" xml:base="http://localhost:4000/kaist_wurf/KAIST_WURF_-%EC%98%A4%EC%A0%84_%EC%86%90%EC%B0%BD%ED%98%B8%EA%B5%90%EC%88%98%EB%8B%98/"><![CDATA[<p class="notice--info">손창호 교수님의 WURF Meet the Professer 강의를 바탕으로 정리하였습니다.</p>
<h1 id="개요">개요</h1>

<p>손창호 교수님</p>

<ul>
  <li><strong>전공</strong>: 물리화학</li>
  <li><strong>연구</strong>: 공간전사체</li>
  <li><strong>주요 연구</strong>: FX-seq의 응용 및 단일세포 전사체 RNA 시퀀싱</li>
</ul>

<p><br /></p>

<h1 id="1-암의-cellular-heterogeneity-novel-technology-driven-innovation-for-next-generation-biomedical-sciences">1. 암의 Cellular Heterogeneity: Novel Technology-Driven Innovation for Next-Generation Biomedical Sciences</h1>

<h2 id="11-sequence-based-vs-image-based-approaches">1.1 Sequence-Based vs Image-Based Approaches</h2>

<h3 id="연구-철학">연구 철학</h3>
<ul>
  <li><strong>Alexander Varshavsky</strong>: “새로운 발견은 새로운 방법의 결과이다.”</li>
  <li>연구실 비전: 새로운 방법론 개발을 통한 혁신.</li>
</ul>

<h2 id="12-fx-seq-for-ffpe-tissues-in-snrnaseq">1.2 FX-seq for FFPE Tissues in snRNAseq</h2>

<h3 id="121-한계점">1.2.1 한계점</h3>
<ol>
  <li><strong>조직 가용성</strong>: 작은 종양, 수술 지연, 병원-실험실 거리 문제.</li>
  <li><strong>데이터 가용성</strong>: 불확실한 종양 진단, 처리 지연.</li>
</ol>

<h3 id="122-주요-질문">1.2.2 주요 질문</h3>
<ul>
  <li>Translational single-cell 연구:
    <ol>
      <li>장기 생존자 vs 단기 생존자.</li>
      <li>표적 치료 반응자 vs 비반응자.</li>
      <li>Driver mutation 비교.</li>
    </ol>
  </li>
</ul>

<h3 id="123-ffpe-조직의-병리학적-분석">1.2.3 FFPE 조직의 병리학적 분석</h3>
<ul>
  <li><strong>문제점</strong>: 포르말린(PFA) 처리된 샘플은 역전사효소가 인지하지 못해 cDNA 합성이 어려움.</li>
  <li><strong>해결책</strong>: FX-seq with snRNAseq:
    <ul>
      <li>RNA anchoring 후, cDNA 합성을 방해하는 부위를 가수분해하는 효소 개발.</li>
    </ul>
  </li>
</ul>

<h3 id="124-인간-샘플-응용">1.2.4 인간 샘플 응용</h3>
<ul>
  <li><strong>도전 과제</strong>:
    <ul>
      <li>Mouse data와 human aging data의 차이.</li>
      <li>외국에서 고품질 샘플 확보의 어려움.</li>
      <li>희귀 질환의 경우 fresh data 부족.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="2-ai-modeling-in-biomedical-sciences">2. AI Modeling in Biomedical Sciences</h1>

<h2 id="21-random-primer-기반-cdna-합성">2.1 Random Primer 기반 cDNA 합성</h2>
<ul>
  <li><strong>기술</strong>: 어떤 서열 부위든 데이터 확보 가능.</li>
</ul>

<h2 id="22-ai와-항체-설계">2.2 AI와 항체 설계</h2>
<ul>
  <li><strong>RF Diffusion</strong>: 알파폴드로 항체 PDB 데이터 부족 문제 해결.</li>
  <li><strong>기술 발전</strong>:
    <ul>
      <li>CDR 서열 확보 및 RNA 발현 기반 ESM fold fine-tuning.</li>
      <li>LLM 활용 데이터 생성.</li>
    </ul>
  </li>
  <li><strong>한계</strong>:
    <ul>
      <li>Open target 예측 불가.</li>
      <li>선구 물질 탐색과 면역 반응 예측 모두 필요.</li>
    </ul>
  </li>
</ul>

<h2 id="23-medical-ai">2.3 Medical AI</h2>
<ul>
  <li><strong>응용 분야</strong>:
    <ul>
      <li>Medical imaging 기반 진단.</li>
      <li>DNA 시퀀싱 및 단일세포 질병 연구.</li>
      <li>메타 데이터 및 멀티모달 데이터 분석.</li>
      <li>항체 및 소분자 설계.</li>
    </ul>
  </li>
  <li><strong>현재 문제</strong>:
    <ul>
      <li>높은 계산 자원 요구.</li>
      <li>AI 도구 표준화 부재.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h1 id="정리">정리</h1>

<p>교수님께서는 ‘물리화학’이라는 다른 전공분야에서 의과학대학원으로 오시기까지의 과정을 말씀하시며, Cross-Platform Study의 중요성을 강조하셨다. 다른 분야의 연구를 했기에 기존 연구자들이 보지 못한 시각과 네트워크를 활용할 수 있었다고 하셨다. 또한 점과 점을 연결하는 아이디어의 중요성을 말씀하셨다.</p>

<p>다양한 배경의 연구자들이 새로운 분야에 도전할 때, 혁신은 이루어진다. 내 분야와 어떻게 시너지를 낼 수 있을까?를 항상 고민해야겠다고 다짐하였다.</p>]]></content><author><name>DaRe_jin</name></author><category term="[&quot;KAIST_WURF&quot;]" /><category term="일지" /></entry></feed>